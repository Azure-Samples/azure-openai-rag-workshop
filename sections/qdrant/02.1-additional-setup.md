## Complete the setup

To complete the template setup, please run the following command in a terminal, at the root of the project:

```bash
./scripts/setup-template.sh qdrant
```

### Preparing the environment

<div data-visible="$$proxy$$">

We have deployed an Open AI proxy service for you, so you can use it to work on this workshop locally before deploying anything to Azure.

Create a `.env` file at the root of the project, and add the following content:

```
AZURE_OPENAI_API_ENDPOINT=$$proxy$$
QDRANT_URL=http://localhost:6333
```

</div>

<div data-hidden="$$proxy$$">

Now you either have to deploy an Azure Open AI service to use the OpenAI API, or you can use a local emulator based on Ollama and an open-source LLM.

#### Using Azure Open AI

You first need to deploy an Azure Open AI service to use the OpenAI API.

Before moving to the next section, go to the **Azure setup** section (either on the left or using the "hamburger" menu depending of your device) to deploy the necessary resources and create your `.env` file needed.

After you completed the Azure setup, come back here to continue the workshop.

At this point you should have a `.env` file at the root of the project. Within that file, replace the line:

```
QDRANT_URL="<some_url>"
```

With:
  
```
QDRANT_URL="http://localhost:6333"
```

#### (Optional) Using Ollama and ollamazure

If you have a machine with enough resources, you can run this workshop entirely locally without using any cloud resources. To do that, you first have to install [Ollama](https://ollama.com) and then run the following commands to download the models on your machine:

```bash
ollama pull phi3
ollama pull all-minilm:l6-v2
```

<div class="info" data-title="Note">

> The `phi3` model with download a few gigabytes of data, so it can take some time depending on your internet connection.

</div>

<div class="important" data-title="Important">

> Ollama work in GitHub Codespaces, but runs very slow currently. If you want to use the Ollama option, it will work best if you are working on the workshop on your local machine directly.

</div>

Once the model are downloaded, create a `.env` file at the root of the project, and add the following content:

```
AZURE_OPENAI_API_ENDPOINT=http://localhost:4041
QDRANT_URL=http://localhost:6333
```

Finally, run this command to start the Azure OpenAI emulator and leave it running in the background:

```bash
npx -y ollamazure
```

</div>
